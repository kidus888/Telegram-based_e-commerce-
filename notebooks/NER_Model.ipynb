{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14904,"status":"ok","timestamp":1727768275050,"user":{"displayName":"KIdus mesele","userId":"14631280397181120254"},"user_tz":0},"id":"UsuZHytF6kR3","outputId":"7bbd4d39-01ab-4602-92c3-3f2a84c30a6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Collecting datasets\n","  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n","INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=79dfb05b831084ce600cf75c983f9e57eb65687c569f9708df257a5bc74714b8\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built seqeval\n","Installing collected packages: xxhash, pyarrow, dill, multiprocess, seqeval, datasets\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 seqeval-1.2.2 xxhash-3.5.0\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install transformers datasets seqeval\n","!pip install torch --upgrade"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26705,"status":"ok","timestamp":1727768349332,"user":{"displayName":"KIdus mesele","userId":"14631280397181120254"},"user_tz":0},"id":"WfN2C7O698rI","outputId":"3af85e12-b298-4579-d501-0af57e3723a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":1304,"status":"ok","timestamp":1727770414665,"user":{"displayName":"KIdus mesele","userId":"14631280397181120254"},"user_tz":0},"id":"zxjR7FJYHPVe"},"outputs":[],"source":["import pandas as pd\n","from datasets import load_dataset, Dataset, DatasetDict\n","from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\n","from transformers import DataCollatorForTokenClassification\n","from sklearn.model_selection import train_test_split\n","import torch\n","import numpy as np\n","from seqeval.metrics import classification_report"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":528,"status":"ok","timestamp":1727770475238,"user":{"displayName":"KIdus mesele","userId":"14631280397181120254"},"user_tz":0},"id":"G7ysQfOOJHej"},"outputs":[],"source":["def read_conll(file_path):\n","    \"\"\"\n","    Parses a CoNLL file into a DataFrame with two columns: 'words' and 'labels'.\n","    \"\"\"\n","    words, labels = [], []\n","    with open(file_path, 'r') as file:\n","        word_list, label_list = [], []\n","        for line in file:\n","            if line.strip():\n","                word, label = line.strip().split()\n","                word_list.append(word)\n","                label_list.append(label)\n","            else:\n","                if word_list:  # End of a sentence\n","                    words.append(word_list)\n","                    labels.append(label_list)\n","                    word_list, label_list = [], []\n","    return pd.DataFrame({\"words\": words, \"labels\": labels})\n","\n","# Load your dataset in CoNLL format\n","conll_data = read_conll(\"/content/drive/MyDrive/labeled_data.conll\")\n","\n","# Split into train and validation set\n","train_df, val_df = train_test_split(conll_data, test_size=0.2)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3913,"status":"ok","timestamp":1727770546970,"user":{"displayName":"KIdus mesele","userId":"14631280397181120254"},"user_tz":0},"id":"vu96hSgpJYvl","outputId":"797ec902-ff31-4e84-e633-2efce8e35989"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["def convert_to_hf_format(df):\n","    return Dataset.from_pandas(df)\n","\n","train_dataset = convert_to_hf_format(train_df)\n","val_dataset = convert_to_hf_format(val_df)\n","\n","#  Load the tokenizer and model\n","model_checkpoint = \"xlm-roberta-base\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=10)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["b8807cd6d49544d5860ebc4f99aad807","dc480b0069b5456ba90d40a4a197e46d","90f2436126ee4ee6a8113434b2159a13","ec69764c46124eac8ab678d9b684403f","a33d52329d554828ad9b45a101e003ff","3a21e62789ec46d7bd8a74183afd64b9","288f47d23dc342eab66bf86a6934b09c","ee0d214437a14d57820fa0f5df7ab96a","b34c00e88e9d485dbd11a64f4ef76fd2","52b4f6dbbab5472ab96d3ad8daa6ba0b","4f87e5efa5a043f49d160cd3c9e83f67","b04959e6108f490b8b250006a09ef299","4e38d2723a5244c18b9c120553bd7df1","bc732a9351ca4377a6ffc4c73479b835","c4472b9ebe05488584a9b4bdcbe7942e","09d0f8081e1d4f0e8570555c9fec50e3","5171435f12014ee88f6d7e3611df70d4","4608aeeb6f784961a0d6e985633c8347","e6e25f2ba48a464891fcab92ff4c7e95","ec0e58e581e642bab754ef062c20e085","6d0e6700a8e143db8a67ef5fc174bcec","ef37dad14083410da414d7ed1c34ae4d"]},"executionInfo":{"elapsed":3329,"status":"ok","timestamp":1727770723394,"user":{"displayName":"KIdus mesele","userId":"14631280397181120254"},"user_tz":0},"id":"ltcfBsXqJr02","outputId":"f2b448d4-b3a1-40a7-9ffe-1accc6315fa5"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8807cd6d49544d5860ebc4f99aad807","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/581 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b04959e6108f490b8b250006a09ef299","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/146 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["#  Extract the unique labels from the dataset\n","label_list = sorted(list(set([label for sublist in conll_data['labels'] for label in sublist])))\n","label_to_id = {label: idx for idx, label in enumerate(label_list)}\n","id_to_label = {idx: label for label, idx in label_to_id.items()}\n","\n","#  Tokenize and align labels, but first convert the labels to their integer form\n","def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(examples[\"words\"], truncation=True, is_split_into_words=True)\n","\n","    labels = []\n","    for i, label in enumerate(examples[\"labels\"]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            elif word_idx != previous_word_idx:  # Start of a new word\n","                label_ids.append(label_to_id[label[word_idx]])  # Convert label to its integer ID\n","            else:\n","                label_ids.append(-100)\n","            previous_word_idx = word_idx\n","        labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs\n","\n","# Apply the tokenization and alignment to both training and validation datasets\n","train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n","val_dataset = val_dataset.map(tokenize_and_align_labels, batched=True)\n","\n","#  Make sure to update the model's number of labels\n","num_labels = len(label_list)\n","model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n","\n","#  Metrics calculation function (for evaluation)\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    true_labels = [[id_to_label[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [id_to_label[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    return {\n","        \"classification_report\": classification_report(true_labels, true_predictions),\n","    }\n"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":460,"status":"ok","timestamp":1727770813665,"user":{"displayName":"KIdus mesele","userId":"14631280397181120254"},"user_tz":0},"id":"-kgmXtHzKk43","outputId":"0257b71a-b05f-4fa6-d3ab-c26e3ce53968"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["#  Set up training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    save_strategy=\"epoch\",\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":953},"executionInfo":{"elapsed":256831,"status":"ok","timestamp":1727771095187,"user":{"displayName":"KIdus mesele","userId":"14631280397181120254"},"user_tz":0},"id":"Vj5NrXY-KpCe","outputId":"02556813-ad37-441a-d1c4-85a3c127e82a"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='111' max='111' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [111/111 04:10, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Classification Report</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.159800</td>\n","      <td>0.118470</td>\n","      <td>              precision    recall  f1-score   support\n","\n","         LOC       0.58      0.79      0.67       185\n","       PRICE       0.00      0.00      0.00        89\n","     Product       0.00      0.00      0.00       100\n","\n","   micro avg       0.58      0.39      0.47       374\n","   macro avg       0.19      0.26      0.22       374\n","weighted avg       0.29      0.39      0.33       374\n","</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.054800</td>\n","      <td>0.046988</td>\n","      <td>              precision    recall  f1-score   support\n","\n","         LOC       0.93      0.92      0.93       185\n","       PRICE       0.97      0.94      0.95        89\n","     Product       0.00      0.00      0.00       100\n","\n","   micro avg       0.94      0.68      0.79       374\n","   macro avg       0.63      0.62      0.63       374\n","weighted avg       0.69      0.68      0.69       374\n","</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.041700</td>\n","      <td>0.037342</td>\n","      <td>              precision    recall  f1-score   support\n","\n","         LOC       0.93      0.91      0.92       185\n","       PRICE       0.94      0.94      0.94        89\n","     Product       0.60      0.03      0.06       100\n","\n","   micro avg       0.93      0.68      0.79       374\n","   macro avg       0.83      0.63      0.64       374\n","weighted avg       0.85      0.68      0.70       374\n","</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n","\n","         LOC       0.58      0.79      0.67       185\n","       PRICE       0.00      0.00      0.00        89\n","     Product       0.00      0.00      0.00       100\n","\n","   micro avg       0.58      0.39      0.47       374\n","   macro avg       0.19      0.26      0.22       374\n","weighted avg       0.29      0.39      0.33       374\n","\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n","\n","         LOC       0.93      0.92      0.93       185\n","       PRICE       0.97      0.94      0.95        89\n","     Product       0.00      0.00      0.00       100\n","\n","   micro avg       0.94      0.68      0.79       374\n","   macro avg       0.63      0.62      0.63       374\n","weighted avg       0.69      0.68      0.69       374\n","\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n","\n","         LOC       0.93      0.91      0.92       185\n","       PRICE       0.94      0.94      0.94        89\n","     Product       0.60      0.03      0.06       100\n","\n","   micro avg       0.93      0.68      0.79       374\n","   macro avg       0.83      0.63      0.64       374\n","weighted avg       0.85      0.68      0.70       374\n","\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"text/plain":["TrainOutput(global_step=111, training_loss=0.1960782829235803, metrics={'train_runtime': 254.9062, 'train_samples_per_second': 6.838, 'train_steps_per_second': 0.435, 'total_flos': 272101326973806.0, 'train_loss': 0.1960782829235803, 'epoch': 3.0})"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["#  Fine-tune the model using Hugging Face Trainer\n","data_collator = DataCollatorForTokenClassification(tokenizer)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"elapsed":3692,"status":"ok","timestamp":1727771118674,"user":{"displayName":"KIdus mesele","userId":"14631280397181120254"},"user_tz":0},"id":"-36xnDV6Lu5w","outputId":"4f5beff0-176c-45d9-faa2-ce9383d65385"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10/10 00:02]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"              precision    recall  f1-score   support\n","\n","         LOC       0.93      0.91      0.92       185\n","       PRICE       0.94      0.94      0.94        89\n","     Product       0.60      0.03      0.06       100\n","\n","   micro avg       0.93      0.68      0.79       374\n","   macro avg       0.83      0.63      0.64       374\n","weighted avg       0.85      0.68      0.70       374\n","\" of type <class 'str'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]}],"source":["#  Evaluate the model\n","results = trainer.evaluate()"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7862,"status":"ok","timestamp":1727771149268,"user":{"displayName":"KIdus mesele","userId":"14631280397181120254"},"user_tz":0},"id":"u6e8b2fzLslT","outputId":"f18f2f56-fbce-467b-81a0-a39ff748527c"},"outputs":[{"data":{"text/plain":["('./fine_tuned_model/tokenizer_config.json',\n"," './fine_tuned_model/special_tokens_map.json',\n"," './fine_tuned_model/sentencepiece.bpe.model',\n"," './fine_tuned_model/added_tokens.json',\n"," './fine_tuned_model/tokenizer.json')"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["#  Save the model\n","trainer.save_model(\"./fine_tuned_model\")\n","tokenizer.save_pretrained(\"./fine_tuned_model\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/kidus888/Telegram-based_e-commerce-/blob/task-3/notebooks/NER_Model.ipynb","timestamp":1727719060138}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"09d0f8081e1d4f0e8570555c9fec50e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"288f47d23dc342eab66bf86a6934b09c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a21e62789ec46d7bd8a74183afd64b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4608aeeb6f784961a0d6e985633c8347":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e38d2723a5244c18b9c120553bd7df1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5171435f12014ee88f6d7e3611df70d4","placeholder":"​","style":"IPY_MODEL_4608aeeb6f784961a0d6e985633c8347","value":"Map: 100%"}},"4f87e5efa5a043f49d160cd3c9e83f67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5171435f12014ee88f6d7e3611df70d4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52b4f6dbbab5472ab96d3ad8daa6ba0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d0e6700a8e143db8a67ef5fc174bcec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90f2436126ee4ee6a8113434b2159a13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee0d214437a14d57820fa0f5df7ab96a","max":581,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b34c00e88e9d485dbd11a64f4ef76fd2","value":581}},"a33d52329d554828ad9b45a101e003ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b04959e6108f490b8b250006a09ef299":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e38d2723a5244c18b9c120553bd7df1","IPY_MODEL_bc732a9351ca4377a6ffc4c73479b835","IPY_MODEL_c4472b9ebe05488584a9b4bdcbe7942e"],"layout":"IPY_MODEL_09d0f8081e1d4f0e8570555c9fec50e3"}},"b34c00e88e9d485dbd11a64f4ef76fd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8807cd6d49544d5860ebc4f99aad807":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc480b0069b5456ba90d40a4a197e46d","IPY_MODEL_90f2436126ee4ee6a8113434b2159a13","IPY_MODEL_ec69764c46124eac8ab678d9b684403f"],"layout":"IPY_MODEL_a33d52329d554828ad9b45a101e003ff"}},"bc732a9351ca4377a6ffc4c73479b835":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6e25f2ba48a464891fcab92ff4c7e95","max":146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec0e58e581e642bab754ef062c20e085","value":146}},"c4472b9ebe05488584a9b4bdcbe7942e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d0e6700a8e143db8a67ef5fc174bcec","placeholder":"​","style":"IPY_MODEL_ef37dad14083410da414d7ed1c34ae4d","value":" 146/146 [00:00&lt;00:00, 207.30 examples/s]"}},"dc480b0069b5456ba90d40a4a197e46d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a21e62789ec46d7bd8a74183afd64b9","placeholder":"​","style":"IPY_MODEL_288f47d23dc342eab66bf86a6934b09c","value":"Map: 100%"}},"e6e25f2ba48a464891fcab92ff4c7e95":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec0e58e581e642bab754ef062c20e085":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec69764c46124eac8ab678d9b684403f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52b4f6dbbab5472ab96d3ad8daa6ba0b","placeholder":"​","style":"IPY_MODEL_4f87e5efa5a043f49d160cd3c9e83f67","value":" 581/581 [00:01&lt;00:00, 519.88 examples/s]"}},"ee0d214437a14d57820fa0f5df7ab96a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef37dad14083410da414d7ed1c34ae4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
